{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41d505fe",
   "metadata": {},
   "source": [
    "# Set up for model experiments\n",
    "\n",
    "We'll do the following here:\n",
    "\n",
    "- Create distinct catalogs\n",
    "- Document parameters changes that will accompany each\n",
    "- Create yamls for each experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9503d4da",
   "metadata": {},
   "source": [
    "# Catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3027a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import os\n",
    "import re\n",
    "import glob \n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4400d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pd.read_csv(\"../data/ftw-mappingafrica-combined-catalog.csv\")\n",
    "catalog.query(\"dataset == 'ftw'\").to_csv(\"../data/ftw-catalog.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe896479",
   "metadata": {},
   "source": [
    "## Single Time Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e89cb",
   "metadata": {},
   "source": [
    "#### Combined catalogs\n",
    "\n",
    "Including small test catalogs \n",
    "\n",
    "Update: catalog will be adjusted to drop Portugal and presence-only data from validation set for FTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33704f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pd.read_csv(\"../data/ftw-mappingafrica-combined-catalog.csv\")\n",
    "# catalog[\"split\"]\n",
    "\n",
    "# 22 records in India had no split assigned--placed them in train\n",
    "catalog[\"split\"] = catalog[\"split\"].replace(\"none\", \"train\")\n",
    "\n",
    "catalog['split'] = catalog['split'].astype(str).str.strip().str.lower()\n",
    "catalog['country'] = catalog['country'].astype(str).str.strip().str.lower()\n",
    "catalog['null_prop'] = pd.to_numeric(catalog['null_prop'], errors='coerce')  # NaN if non-numeric\n",
    "\n",
    "mask = ~(\n",
    "    catalog['split'].isin(['validate', 'test'])\n",
    "    & (\n",
    "        (catalog['null_prop'] > 0) | (catalog['country'] == 'portugal')\n",
    "    )\n",
    ")\n",
    "catalogr = catalog[mask].copy().reset_index(drop=True)\n",
    "\n",
    "# FTW and full catalogs dropping Portugal and presence-only data from val/test\n",
    "(catalogr.query(\"dataset == 'ftw'\")\n",
    " .to_csv(\"../data/ftw-catalog2.csv\", index=False))\n",
    "(catalogr\n",
    " .to_csv(\"../data/ftw-mappingafrica-combined-catalog2.csv\", index=False))\n",
    "\n",
    "# small FTW for rapid model testing\n",
    "ftw_small = (\n",
    "    catalogr\n",
    "     .query(\"dataset == 'ftw'\")\n",
    "     .sample(10000, random_state=42)\n",
    ").reset_index(drop=True)#.to_csv(\"../data/ftw-catalog-small.csv\", index=False))\n",
    "# ftw_small[\"split\"].value_counts()\n",
    "ftw_small.to_csv(\"../data/ftw-catalog-small.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657a499",
   "metadata": {},
   "source": [
    "Make another small catalog for debugging, including null prop > 0 in validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed3dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftw_catalog = pd.read_csv(\"../data/ftw-catalog.csv\")\n",
    "ftw_small_debug = (ftw_catalog\n",
    "                   .sample(1000, random_state=42)\n",
    "                   .reset_index(drop=True))\n",
    "# ftw_small_debug.query(\"split == 'validate' & null_prop > 0\")\n",
    "ftw_small_debug.to_csv(\"../data/ftw-catalog-small-debug.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9cc2c2",
   "metadata": {},
   "source": [
    "#### Mapping Africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d06f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pd.read_csv(\"../data/ftw-mappingafrica-combined-catalog.csv\")\n",
    "(catalog.query(\"dataset == 'mappingafrica'\")\n",
    " .to_csv(\"../data/mappingafrica-catalog.csv\", index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b8c2b4",
   "metadata": {},
   "source": [
    "Mapping Africa countries with >30 validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f511fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_catalog = pd.read_csv(\"../data/mappingafrica-catalog.csv\")\n",
    "ma_countries = (ma_catalog.query(\"split == 'validate'\")\n",
    " .country\n",
    " .value_counts()\n",
    " .reset_index()\n",
    " .query(\"count > 30\")\n",
    " .sort_values(\"country\")\n",
    " .drop(\"count\", axis=1)\n",
    " )\n",
    "with open(\"../scripts/ma-countries.txt\", \"w\") as f:\n",
    "    for c in ma_countries.country.tolist():\n",
    "        f.write(f\"{c}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06ba72",
   "metadata": {},
   "source": [
    "#### Inference catalogs \n",
    "\n",
    "For inference testing, both chips and tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9e2776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>window_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>513706</td>\n",
       "      <td>2023-11-15</td>\n",
       "      <td>2023/tile513706_2023-11_buf179_cog.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>513726</td>\n",
       "      <td>2023-11-15</td>\n",
       "      <td>2023/tile513726_2023-11_buf179_cog.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>765503</td>\n",
       "      <td>2022-03-15</td>\n",
       "      <td>2022/tile765503_2022-03_buf179_cog.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910217</td>\n",
       "      <td>2024-06-15</td>\n",
       "      <td>2024/tile910217_2024-06_buf179_cog.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>910218</td>\n",
       "      <td>2024-06-15</td>\n",
       "      <td>2024/tile910218_2024-06_buf179_cog.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name        date                                window_b\n",
       "0  513706  2023-11-15  2023/tile513706_2023-11_buf179_cog.tif\n",
       "1  513726  2023-11-15  2023/tile513726_2023-11_buf179_cog.tif\n",
       "2  765503  2022-03-15  2022/tile765503_2022-03_buf179_cog.tif\n",
       "3  910217  2024-06-15  2024/tile910217_2024-06_buf179_cog.tif\n",
       "4  910218  2024-06-15  2024/tile910218_2024-06_buf179_cog.tif"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# # Recursively find all files in /Users/lestes/images/tiles and subfolders\n",
    "tiles_list = [\n",
    "    os.path.relpath(f, \"/Users/lestes/images/tiles\")\n",
    "    for f in glob.glob(\"/Users/lestes/images/tiles/**/*\", recursive=True)\n",
    "    if os.path.isfile(f) and f.endswith(\"cog.tif\")\n",
    "    # (os.path.basename(f).startswith((\"tile910\", \"tile513\", \"tile765\"))      \n",
    "]\n",
    "\n",
    "# tile numbers of interest\n",
    "tile_ids = [\"910217\", \"910218\", \"513706\", \"513726\", \"765503\"]  \n",
    "\n",
    "# Filter tiles_list for specified tile_ids and keep only the last (latest year) \n",
    "# For each tile_id, keep only the image from the most recent year (folder)\n",
    "tile_dict = {}\n",
    "for f in tiles_list:\n",
    "  basename = os.path.basename(f)\n",
    "  for tid in tile_ids:\n",
    "    if basename.startswith(f\"tile{tid}\"):\n",
    "      year_folder = os.path.dirname(f)\n",
    "      try:\n",
    "        year_int = int(year_folder)\n",
    "      except ValueError:\n",
    "        continue  # skip if folder is not a year\n",
    "      # Keep the file if it's the first seen or has a greater year\n",
    "      if tid not in tile_dict or year_int > int(os.path.dirname(tile_dict[tid])):\n",
    "        tile_dict[tid] = f\n",
    "tiles_selected = list(tile_dict.values())\n",
    "                 \n",
    "tile_catalog = pd.DataFrame(\n",
    "    [{\"name\": re.sub(\"tile\", \"\", os.path.basename(f).split(\"_\")[0]),  \n",
    "      # \"year\": os.path.dirname(f), \n",
    "      \"date\": f\"{os.path.basename(f).split(\"_\")[1]}-15\",\n",
    "      \"window_b\": f}\n",
    "      for f in tiles_selected]\n",
    ").sort_values(by=[\"name\", \"date\"]).reset_index(drop=True)\n",
    "# tile_catalog.to_csv(\"../data/mappingafrica-tile-catalog.csv\", index=False)\n",
    "# (tile_catalog.query(\"name in ['910217', '910218'] & year == '2024'\")\n",
    "#  .to_csv(\"../data/mappingafrica-tile-catalog-small.csv\", index=False))\n",
    "\n",
    "tile_catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdee0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = \"~/Dropbox/projects/activelearning/mappingafrica/campaigns/data/grids\"\n",
    "tiles = [gpd.read_file(f\"{pth}/{cntry}_tiles.geojson\")[[\"tile\", \"geometry\"]] \n",
    "         for cntry in [\"ghana\", \"congo\", \"zambia\"]]\n",
    "tiles = pd.concat(tiles, axis=0)\n",
    "tiles[\"tile\"] = tiles[\"tile\"].astype(int).astype(str)\n",
    "tiles = tiles.query(\"tile in @tile_ids\").reset_index(drop=True)\n",
    "\n",
    "tiles_gdf = (\n",
    "    pd.merge(tile_catalog, tiles, left_on=\"name\", right_on=\"tile\", how=\"inner\")\n",
    "    .drop(columns=[\"tile\"])\n",
    "    .pipe(gpd.GeoDataFrame, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    ")\n",
    "tiles_gdf.to_file(\"../data/mappingafrica-tile-catalog-small.geojson\", \n",
    "                  driver=\"GeoJSON\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c9316",
   "metadata": {},
   "source": [
    "#### FTW long\n",
    "\n",
    "Make catalog placing FTW win_a labels under win_b to let model learn from both time points. Make new combined catalog. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "344b5c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftw_catalog = catalog.query(\"dataset == 'ftw'\")\n",
    "ftw_catalog2 = ftw_catalog.copy()\n",
    "ftw_catalog2[\"window_b\"] = ftw_catalog2[\"window_a\"]\n",
    "ftw_catalog_long = (pd.concat([ftw_catalog, ftw_catalog2], axis=0)\n",
    "                    .reset_index(drop=True))\n",
    "ftw_catalog_long[\"window_a\"] = \"\"\n",
    "# .to_csv(\"../data/ftw-mappingafrica-combined-catalog.csv\", index=False)\n",
    "\n",
    "# Long FTW catalog\n",
    "ftw_catalog_long.to_csv(\"../data/ftw-catalog-long.csv\", index=False)\n",
    "\n",
    "# Long combined\n",
    "catalog_long = pd.concat([ftw_catalog_long, \n",
    "                          catalog.query(\"dataset == 'mappingafrica'\")], axis=0)\n",
    "# list(catalog_long.shape)\n",
    "# catalog_long.head()\n",
    "catalog_long.to_csv(\"../data/ftw-mappingafrica-combined-catalog-long.csv\", \n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de87945",
   "metadata": {},
   "source": [
    "And new catalog that drops from validation set all presence-only data, but keeping Portugal this time in one (long2), and for consistency with previous dropping Portugal and presence only in the others (long3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab5ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~(\n",
    "    catalog_long['split'].isin(['validate', 'test'])\n",
    "    & (catalog_long['null_prop'] > 0) \n",
    ")\n",
    "\n",
    "catalogr = catalog_long[mask].copy().reset_index(drop=True)\n",
    "print(len(catalogr), len(catalog_long))\n",
    "\n",
    "(catalogr\n",
    " .to_csv(\"../data/ftw-mappingafrica-combined-catalog-long2.csv\", index=False))\n",
    "\n",
    "(catalogr.query(\"dataset == 'ftw'\")\n",
    " .to_csv(\"../data/ftw-catalog-long2.csv\", index=False))\n",
    "\n",
    "mask = ~(\n",
    "    catalog_long['split'].isin(['validate', 'test'])\n",
    "    & (\n",
    "        (catalog_long['null_prop'] > 0) | \n",
    "        (catalog_long['country'] == 'portugal')\n",
    "    )\n",
    ")\n",
    "\n",
    "catalogr = catalog_long[mask].copy().reset_index(drop=True)\n",
    "print(len(catalogr), len(catalog_long))\n",
    "\n",
    "(catalogr\n",
    " .to_csv(\"../data/ftw-mappingafrica-combined-catalog-long3.csv\", index=False))\n",
    "\n",
    "(catalogr.query(\"dataset == 'ftw'\")\n",
    " .to_csv(\"../data/ftw-catalog-long3.csv\", index=False))\n",
    "\n",
    "catalogr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e748a89d",
   "metadata": {},
   "source": [
    "FTW country list for validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dddd500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftw_catalog_long = pd.read_csv(\n",
    "    \"../data/ftw-catalog-long3.csv\"\n",
    ")\n",
    "ftw_countries = (ftw_catalog_long.query(\"split == 'validate'\")\n",
    " .country\n",
    " .value_counts()\n",
    " .reset_index()\n",
    " .sort_values(\"country\")\n",
    " .drop(\"count\", axis=1)\n",
    " )\n",
    "with open(\"../scripts/ftw-countries.txt\", \"w\") as f:\n",
    "    for c in ftw_countries.country.tolist():\n",
    "        f.write(f\"{c}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1fa8c4",
   "metadata": {},
   "source": [
    "#### Mapping Africa and Full Catalogs with S2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "004e2db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>window_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AO0045466</td>\n",
       "      <td>2021-10-09</td>\n",
       "      <td>AO0045466_S2L2A_nomask.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AO0049230</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>AO0049230_S2L2A_nomask.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AO0068052</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>AO0068052_S2L2A_nomask.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AO0220548</td>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>AO0220548_S2L2A_nomask.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AO0277614</td>\n",
       "      <td>2023-10-04</td>\n",
       "      <td>AO0277614_S2L2A_nomask.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39064</th>\n",
       "      <td>ZW1290563</td>\n",
       "      <td>2022-06-05</td>\n",
       "      <td>ZW1290563_S2L2A_nomask.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39065</th>\n",
       "      <td>ZW1323816</td>\n",
       "      <td>2022-06-05</td>\n",
       "      <td>ZW1323816_S2L2A_nomask.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39066</th>\n",
       "      <td>ZW1327144</td>\n",
       "      <td>2022-06-02</td>\n",
       "      <td>ZW1327144_S2L2A_nomask.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39067</th>\n",
       "      <td>ZW1330078</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>ZW1330078_S2L2A_nomask.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39068</th>\n",
       "      <td>ZW1333273</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>ZW1333273_S2L2A_nomask.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39069 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name        date                    window_b\n",
       "0      AO0045466  2021-10-09  AO0045466_S2L2A_nomask.tif\n",
       "1      AO0049230  2017-08-19  AO0049230_S2L2A_nomask.tif\n",
       "2      AO0068052  2019-07-30  AO0068052_S2L2A_nomask.tif\n",
       "3      AO0220548  2020-10-29  AO0220548_S2L2A_nomask.tif\n",
       "4      AO0277614  2023-10-04  AO0277614_S2L2A_nomask.tif\n",
       "...          ...         ...                         ...\n",
       "39064  ZW1290563  2022-06-05  ZW1290563_S2L2A_nomask.tif\n",
       "39065  ZW1323816  2022-06-05  ZW1323816_S2L2A_nomask.tif\n",
       "39066  ZW1327144  2022-06-02  ZW1327144_S2L2A_nomask.tif\n",
       "39067  ZW1330078  2018-08-02  ZW1330078_S2L2A_nomask.tif\n",
       "39068  ZW1333273  2020-06-30  ZW1333273_S2L2A_nomask.tif\n",
       "\n",
       "[39069 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_winb_catalog = pd.read_csv(\"../external/inputs/primary_merged_dedup.csv\")\n",
    "s2_winb_catalog.rename(columns={\"chip_id\": \"name\"}, inplace=True)\n",
    "\n",
    "s2_dir = \"/Users/LEstes/data/labels/cropland/mappingafrica-s2-256/window_b\"\n",
    "\n",
    "fns = [f for f in os.listdir(s2_dir)]\n",
    "fns = pd.DataFrame(fns).rename(columns ={0: \"window_b\"})\n",
    "fns[\"name\"] = fns[\"window_b\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "s2_winb_catalog = (\n",
    "    pd.merge(s2_winb_catalog, fns, how=\"left\", on=\"name\")\n",
    "    .rename(columns={\"chip_id\": \"name\", \"s2_primary_date\": \"date\"})\n",
    ")\n",
    "s2_winb_catalog = s2_winb_catalog[[\"name\", \"date\", \"window_b\"]]\n",
    "s2_winb_catalog[\"date\"] = pd.to_datetime(\n",
    "    s2_winb_catalog[\"date\"], utc=True, errors=\"coerce\"\n",
    ").dt.strftime(\"%Y-%m-%d\")\n",
    "s2_winb_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89c5bb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_b</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GH0639365_S2L2A_nomask.tif</td>\n",
       "      <td>GH0639365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MZ0979620_S2L2A_nomask.tif</td>\n",
       "      <td>MZ0979620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZM2491782_S2L2A_nomask.tif</td>\n",
       "      <td>ZM2491782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CG0737271_S2L2A_nomask.tif</td>\n",
       "      <td>CG0737271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NG0935668_S2L2A_nomask.tif</td>\n",
       "      <td>NG0935668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39011</th>\n",
       "      <td>NG1038617_S2L2A_nomask.tif</td>\n",
       "      <td>NG1038617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39012</th>\n",
       "      <td>TD4088262_S2L2A_nomask.tif</td>\n",
       "      <td>TD4088262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39013</th>\n",
       "      <td>CM0221406_S2L2A_nomask.tif</td>\n",
       "      <td>CM0221406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39014</th>\n",
       "      <td>TZ0933296_S2L2A_nomask.tif</td>\n",
       "      <td>TZ0933296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39015</th>\n",
       "      <td>NG0984206_S2L2A_nomask.tif</td>\n",
       "      <td>NG0984206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39016 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         window_b       name\n",
       "0      GH0639365_S2L2A_nomask.tif  GH0639365\n",
       "1      MZ0979620_S2L2A_nomask.tif  MZ0979620\n",
       "2      ZM2491782_S2L2A_nomask.tif  ZM2491782\n",
       "3      CG0737271_S2L2A_nomask.tif  CG0737271\n",
       "4      NG0935668_S2L2A_nomask.tif  NG0935668\n",
       "...                           ...        ...\n",
       "39011  NG1038617_S2L2A_nomask.tif  NG1038617\n",
       "39012  TD4088262_S2L2A_nomask.tif  TD4088262\n",
       "39013  CM0221406_S2L2A_nomask.tif  CM0221406\n",
       "39014  TZ0933296_S2L2A_nomask.tif  TZ0933296\n",
       "39015  NG0984206_S2L2A_nomask.tif  NG0984206\n",
       "\n",
       "[39016 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b82d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_catalog = pd.read_csv(\"../data/mappingafrica-catalog.csv\")\n",
    "list(ma_catalog.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7c22fe",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec63f770",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5343e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_yaml(template_path: str, output_path: str, updates: dict = None):\n",
    "    \"\"\"\n",
    "    Write a YAML file from a template file, with optional updates.\n",
    "\n",
    "    Args:\n",
    "        template_path (str): Path to the base YAML template file.\n",
    "        output_path (str): Path to the output YAML file.\n",
    "        updates (dict, optional): Dictionary of keys/values to update.\n",
    "    \"\"\"\n",
    "\n",
    "    def recursive_update(d, u):\n",
    "        for k, v in u.items():\n",
    "            if isinstance(v, dict) and isinstance(d.get(k), dict):\n",
    "                recursive_update(d[k], v)\n",
    "            else:\n",
    "                d[k] = v\n",
    "\n",
    "    with open(template_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "        if updates:\n",
    "            recursive_update(config, updates)\n",
    "\n",
    "    class IndentDumper(yaml.SafeDumper):\n",
    "        def increase_indent(self, flow=False, indentless=False):\n",
    "            return super().increase_indent(flow, False)\n",
    "\n",
    "    # custom representer for lists\n",
    "    def represent_list(dumper, data):\n",
    "        # flow style only if all elements are scalars\n",
    "        if all(isinstance(x, (str, int, float, bool, type(None))) for x in data):\n",
    "            return dumper.represent_sequence(\"tag:yaml.org,2002:seq\", data, \n",
    "                                             flow_style=True)\n",
    "        else:\n",
    "            return dumper.represent_sequence(\"tag:yaml.org,2002:seq\", data, \n",
    "                                             flow_style=False)\n",
    "\n",
    "    IndentDumper.add_representer(list, represent_list)\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        yaml.dump(\n",
    "            config,\n",
    "            f,\n",
    "            Dumper=IndentDumper,\n",
    "            default_flow_style=False,  # keep dicts block-style\n",
    "            sort_keys=False,\n",
    "            indent=2,\n",
    "            allow_unicode=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df948ae8",
   "metadata": {},
   "source": [
    "## Naming conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67e2a1b",
   "metadata": {},
   "source": [
    "Model config files are general named according to the following recipe:\n",
    "\n",
    "- `<model>_<backbone>-<loss>-<norm>-<augmentation>-<epochs><-patience>-<catalog>`\n",
    "\n",
    "Although this recipe has varied a bit as experiments have evolved, primarily in the early phase where different settings were being evaluated, and as efforts to shorten names were applied (the config is applied to model outputs folders and metrics files, which become cumbersome).\n",
    "\n",
    "The pattern above is generally for models trained on just the FTW dataset, where there were different permutations of the single time point catalog initially (window_b only and window_b + window_a combined under window_b [long catalogs]).  \n",
    "\n",
    "For other catalogs--full and Mapping Africa only--the recipe is as follows:\n",
    "\n",
    "- `<full|ma>-<model>_<backbone>-<loss>-<norm>-<augmentation>-<epochs><-patience>-<catalog>`\n",
    "\n",
    "In all cases, there are variations within most components also. \n",
    "\n",
    "- For FTW baseline architecture models (U-Net with EfficientNet-b3), `<model>_<backbone>` is either simply `ftwbaseline` or `ftwbase`\n",
    "- For the model approximating our standard Mapping Africa architecture (U-Net with VGG19), `<model>_<backbone>` is either `ma-approximate` or `ma-approx` or `ma-approxbase`\n",
    "- For other variants, the full model and backbone names are used, e.g., `unet_cvnxt_sm` or `unet_cvnxt_sm` for U-Net with ConvNeXt Small backbone pretrained on ImageNet-22K. \n",
    "- Losses vary, but are fairly self-explanatory, although locally-weighted tversky focal is often not mentioned (in ma-approx models), where it is standard, or called `localtversky` or `loctver`, and finally `ltfl`.  Similarly weighted cross-entropy is left unmentioned for FTW baselines models. The loss in these cases is only made explicit when different. \n",
    "- The general augmentation are abbreviated out separately, specifying additional augmentations added on top of what FTW used by default (rotation, v and h flips, sharpness). These include `rescale` or `rscl` and `rscl2`, which is rescaling with different parameters, and `brightness` or `brgt`. \n",
    "    - We have settled now onto a standard package that adds brightness and rescaling with FTW settings, so names containg `sta` now indicate the final standard augmentation package. \n",
    "- Epochs are not listed unless longer than 100. Similarly with patience. As both of these should be matched, the standard now for trains longer than 100 is e.g. `ep300` or epochs of 300 with matching patience.\n",
    "- `<catalog>` is not always provided either. Older models runs did not mention this, as they only used window_b. Newer FTW or full catalog runs end typically in `longcat` to show that they use a single window, but the model is shown both window A and B. Later experiments drop this again because all single time point runs involving the FTW catalog now use longcat. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8f8e5",
   "metadata": {},
   "source": [
    "## Single time point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab82bf9",
   "metadata": {},
   "source": [
    "### FTW catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11272502",
   "metadata": {},
   "source": [
    "#### FTW baseline \n",
    "All experiments here are FTW baseline model, window B only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b9f74",
   "metadata": {},
   "source": [
    "##### Setup\n",
    "\n",
    "Below we set up a yaml for each experiment. Provide the following:\n",
    "\n",
    "- `cfg_name`: name of the config/experiment file (without .yaml)\n",
    "- `update`: dictionary of changes to make to the base config\n",
    "\n",
    "Also define a global `home_dir` for the path to the repo containing the catalog. That's done once in the first cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efdbd147",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = \"~/projects\"\n",
    "base_update = dict(\n",
    "    data=dict(\n",
    "        init_args=dict(\n",
    "            catalog=f\"{home_dir}/\"\\\n",
    "                \"ftw-mappingafrica-integration/data/ftw-catalog2.csv\",\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ae23b",
   "metadata": {},
   "source": [
    "##### # 1 Default\n",
    "\n",
    "With updated optimal weights added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f26aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ftwbaseline-exp1\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a414ea3f",
   "metadata": {},
   "source": [
    "##### # 2 Locally-weighted tversky focal loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4def790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ftwbaseline-localtversky-exp2\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(init_args=dict(loss=\"localtversky\"))\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0070ae6",
   "metadata": {},
   "source": [
    "##### # 3 Local min-max normalization, across bands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "41fc1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ftwbaseline-minmax_lab-exp3\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"data\"][\"init_args\"] = dict(\n",
    "    normalization_strategy=\"min_max\",\n",
    "    normalization_stat_procedure=\"lab\",\n",
    "    global_stats=None,\n",
    ")\n",
    "\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2b5861",
   "metadata": {},
   "source": [
    "##### # 3a Local min-max normalization, across bands, 1% clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6dc3ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ftwbaseline-minmax_lab-exp3a\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"data\"][\"init_args\"] = dict(\n",
    "    normalization_strategy=\"min_max\",\n",
    "    normalization_stat_procedure=\"lab\",\n",
    "    img_clip_val=1,\n",
    "    global_stats=None,\n",
    ")\n",
    "\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d22d36",
   "metadata": {},
   "source": [
    "##### # 4 Global min-max normalization, across bands\n",
    "\n",
    "Using the 1st and 99th percentiles as min-max. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "691b64dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ftwbaseline-minmax_gab-exp4\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "\n",
    "# Ensure global_stats exists before popping\n",
    "global_stats = update[\"data\"][\"init_args\"].get(\"global_stats\", {})\n",
    "global_stats.pop(\"mean\", None)\n",
    "global_stats.pop(\"std\", None)\n",
    "update[\"data\"][\"init_args\"][\"global_stats\"] = global_stats\n",
    "\n",
    "update[\"data\"][\"init_args\"].update(dict(\n",
    "    normalization_strategy=\"min_max\",\n",
    "    normalization_stat_procedure=\"gab\",\n",
    "    global_stats={\"min\": [68.438525], \"max\": [5772.288821], \n",
    "                  \"mean\": None, \"std\": None},\n",
    "))\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda8ff6f",
   "metadata": {},
   "source": [
    "##### # 4a Per band Z-value, global stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af940ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ftwbaseline-zvalue_gpb-exp4a\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"data\"][\"init_args\"] = dict(\n",
    "    normalization_stat_procedure=\"gpb\",\n",
    "    global_stats={\"mean\": [874.538, 876.9152, 641.7087, 2925.554], \n",
    "                  \"std\": [759.7574, 648.3951, 619.3338, 1083.3489]},\n",
    ")\n",
    "\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5b5b94",
   "metadata": {},
   "source": [
    "##### # 5 - photometric augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d319c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = [\"rotation\", \"hflip\", \"vflip\", \"sharpness\"]\n",
    "cfg_name = \"ftwbaseline-photometric-exp5\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"data\"][\"init_args\"] = dict(\n",
    "    aug_list=augs + [\"brightness\", \"contrast\", \"gaussian_noise\"]\n",
    ")    \n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc15d2",
   "metadata": {},
   "source": [
    "##### # 6 - satslidemix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d77a451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = [\"rotation\", \"hflip\", \"vflip\", \"sharpness\"]\n",
    "cfg_name = \"ftwbaseline-satslide-exp6\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"data\"][\"init_args\"] = dict(\n",
    "    aug_list=augs + [\"satslidemix\"]\n",
    ")    \n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a211b81",
   "metadata": {},
   "source": [
    "##### # 7 - rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2c7d0e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = [\"rotation\", \"hflip\", \"vflip\", \"sharpness\"]\n",
    "cfg_name = \"ftwbaseline-rescale-exp7\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"data\"][\"init_args\"] = dict(\n",
    "    aug_list=augs + [\"rescale\"]\n",
    ")    \n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41de6de",
   "metadata": {},
   "source": [
    "##### # 8 - Tversky and min-max GAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c3fc86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ftwbaseline-localtversky-minmax_gab-exp8\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(init_args=dict(loss=\"localtversky\"))\n",
    "update[\"data\"][\"init_args\"].update(dict(\n",
    "    normalization_strategy=\"min_max\",\n",
    "    normalization_stat_procedure=\"gab\",\n",
    "    global_stats={\"min\": [68.438525], \"max\": [5772.288821], \n",
    "                  \"mean\": None, \"std\": None},\n",
    "))\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c3958",
   "metadata": {},
   "source": [
    "#### MA Approximate baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "241b35f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ftw-ma-approximate-exp1\"\n",
    "# update = dict(\n",
    "#     data=dict(\n",
    "#         init_args=dict(\n",
    "#             catalog=f\"{home_dir}/\"\\\n",
    "#                 \"ftw-mappingafrica-integration/data/ftw-catalog2.csv\"\n",
    "#         )\n",
    "#     )\n",
    "# )\n",
    "# update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "# write_yaml(\"../configs/ma-approximate-baseline.yaml\", \n",
    "#            f\"../configs/{cfg_name}.yaml\", \n",
    "#            updates=update)\n",
    "\n",
    "augs = [\"rotation\", \"hflip\", \"vflip\", \"sharpness\"]\n",
    "# cfg_name = \"ma-approximate-baseline\"\n",
    "\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "        backbone=\"tu-vgg19_bn.tv_in1k\",\n",
    "        patch_weights=True,\n",
    "        model_kwargs=dict(drop_rate=0.1)\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + \\\n",
    "            [\"brightness\", \"contrast\", \"gaussian_noise\", \"rescale\", \"gamma\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"lab\",\n",
    "        global_stats=None,\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fbdf10",
   "metadata": {},
   "source": [
    "### Mapping Africa catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5acb7201",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = \"~/projects\"\n",
    "augs = [\"rotation\", \"hflip\", \"vflip\", \"sharpness\"]\n",
    "base_update = dict(\n",
    "    data=dict(\n",
    "        init_args=dict(\n",
    "            catalog=f\"{home_dir}/\"\\\n",
    "                \"ftw-mappingafrica-integration/data/mappingafrica-catalog.csv\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8a7fb",
   "metadata": {},
   "source": [
    "#### MA Approximate baseline \n",
    "\n",
    "We will train a model close to the variant we used on Planet imagery for mapping countries in Africa, initially trained on just the Mapping Africa labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed3655c",
   "metadata": {},
   "source": [
    "##### Near default\n",
    "\n",
    "These settings are about as close as possible to those originally used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e59f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = [\"rotation\", \"hflip\", \"vflip\", \"sharpness\"]\n",
    "cfg_name = \"ma-approximate-baseline\"\n",
    "\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "        backbone=\"tu-vgg19_bn.tv_in1k\",\n",
    "        patch_weights=True,\n",
    "        model_kwargs=dict(drop_rate=0.1)\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + \\\n",
    "            [\"brightness\", \"contrast\", \"gaussian_noise\", \"rescale\", \"gamma\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"lab\",\n",
    "        global_stats=None,\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d82466",
   "metadata": {},
   "source": [
    "##### MA approximate with only brightness and rescale\n",
    "\n",
    "Brightness now has 50% probability, and rescale parameters are now different tracking FTW's. This steps it down a bit now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f0c66ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = [\"rotation\", \"hflip\", \"vflip\", \"sharpness\"]\n",
    "cfg_name = \"ma-approxbase-brgt-rescl2\"\n",
    "\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "        backbone=\"tu-vgg19_bn.tv_in1k\",\n",
    "        patch_weights=True,\n",
    "        model_kwargs=dict(drop_rate=0.1)\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + \\\n",
    "            [\"brightness\", \"rescale\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"lab\",\n",
    "        global_stats=None,\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f4ce1a",
   "metadata": {},
   "source": [
    "##### MA approximate, minmax GAB, brightness and rescale\n",
    "\n",
    "Using MA global stats, between 1st and 99th percentiles: \n",
    "\n",
    "- min: 203.544\n",
    "- max: 4590.354"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c02e1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = [\"rotation\", \"hflip\", \"vflip\", \"sharpness\"]\n",
    "cfg_name = \"ma-approxbase-mnmx_gab-brgt-rescl2\"\n",
    "\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "        backbone=\"tu-vgg19_bn.tv_in1k\",\n",
    "        patch_weights=True,\n",
    "        model_kwargs=dict(drop_rate=0.1)\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + \\\n",
    "            [\"brightness\", \"rescale\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [203.544], \"max\": [4590.354], \n",
    "                      \"mean\": None, \"std\": None},\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea59d3c",
   "metadata": {},
   "source": [
    "##### MA approximate, SMP tversky, minmax GAB, brightness and rescale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6da36eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = [\"rotation\", \"hflip\", \"vflip\", \"sharpness\"]\n",
    "cfg_name = \"ma-approx-smptver-mnmx_gab-brgt-rescl2\"\n",
    "\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"tversky\", \n",
    "        backbone=\"tu-vgg19_bn.tv_in1k\",\n",
    "        patch_weights=True,\n",
    "        model_kwargs=dict(drop_rate=0.1)\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"brightness\", \"rescale\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [203.544], \"max\": [4590.354], \n",
    "                      \"mean\": None, \"std\": None},\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc840d1",
   "metadata": {},
   "source": [
    "##### MA approx, logcoshdice, minmax GAB, brightness and rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449eb790",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ma-approx-logcoshdice-mnmx_gab-brgt-rescl2\"\n",
    "\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"logcoshdice\", \n",
    "        backbone=\"tu-vgg19_bn.tv_in1k\",\n",
    "        patch_weights=True,\n",
    "        model_kwargs=dict(drop_rate=0.1)\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + \\\n",
    "            [\"brightness\", \"rescale\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [203.544], \"max\": [4590.354], \n",
    "                      \"mean\": None, \"std\": None},\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce3a50",
   "metadata": {},
   "source": [
    "#### FTW baseline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d51487",
   "metadata": {},
   "source": [
    "##### # 1 Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2189361",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ma-ftwbaseline-exp1\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"data\"][\"init_args\"] = dict(\n",
    "    catalog=f\"{home_dir}/\"\\\n",
    "        f\"ftw-mappingafrica-integration/data/mappingafrica-catalog.csv\"   \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41e8e2a",
   "metadata": {},
   "source": [
    "##### # 2 Min-max, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aca950",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ma-ftwbaseline-exp2\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"data\"][\"init_args\"].update(dict(\n",
    "    normalization_strategy=\"min_max\",\n",
    "    normalization_stat_procedure=\"lab\",\n",
    "    global_stats=None,\n",
    "))\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d81626f",
   "metadata": {},
   "source": [
    "##### FTW baseline with local tversky\n",
    "\n",
    "Let's put this more on an equal footing with the MA approximate baseline with local tversky loss and similar augmentations. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d68580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ma-ftwbase-localtversky-brgt-rescl2\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + \\\n",
    "            [\"brightness\", \"rescale\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"lab\",\n",
    "        global_stats=None,\n",
    "    ) \n",
    ")\n",
    "\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17526615",
   "metadata": {},
   "source": [
    "##### FTW baseline, local tversky, minmax GAB, brightness and rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ef1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ma-ftwbase-loctversky-mnmx_gab-brgt-rescl2\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + \\\n",
    "            [\"brightness\", \"rescale\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [203.544], \"max\": [4590.354], \n",
    "                      \"mean\": None, \"std\": None},\n",
    "    ) \n",
    ")\n",
    "\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37235903",
   "metadata": {},
   "source": [
    "##### FTW baseline, logcoshdice, minmax GAB, brightness and rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "644fe9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ma-ftwbase-logcoshdice-mnmx_gab-brgt-rescl2\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"logcoshdice\", \n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + \\\n",
    "            [\"brightness\", \"rescale\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [203.544], \"max\": [4590.354], \n",
    "                      \"mean\": None, \"std\": None},\n",
    "    ) \n",
    ")\n",
    "\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3738fc",
   "metadata": {},
   "source": [
    "##### FTW baseline, SMP tversky, minmax GAB, brightness and rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ea9367",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ma-ftwbase-smptversky-mnmx_gab-brgt-rescl2\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"tversky\", \n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"brightness\", \"rescale\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [203.544], \"max\": [4590.354], \n",
    "                      \"mean\": None, \"std\": None},\n",
    "    ) \n",
    ")\n",
    "\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8246f1bd",
   "metadata": {},
   "source": [
    "##### FTW baseline, tversky focal, standard augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1e27944",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ma-ftwbase-tfl-mmgab-sta\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"tverskyfocal\", \n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"brightness\", \"rescale\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [203.544], \"max\": [4590.354], \n",
    "                      \"mean\": None, \"std\": None},\n",
    "    ) \n",
    ")\n",
    "\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb96e805",
   "metadata": {},
   "source": [
    "##### FTW baseline, tversky focal CE, standard augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d9a4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ma-ftwbase-tflce-mmgab-sta\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        loss=\"tverskyfocalce\", \n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"brightness\", \"rescale\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [203.544], \"max\": [4590.354], \n",
    "                      \"mean\": None, \"std\": None},\n",
    "    ) \n",
    ")\n",
    "\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92694cd",
   "metadata": {},
   "source": [
    "##### FTW baseline, local tversky focal CE, standard augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c95976b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ma-ftwbase-localtflce-mmgab-sta\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"tverskyfocalce\", \n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"brightness\", \"rescale\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [203.544], \"max\": [4590.354], \n",
    "                      \"mean\": None, \"std\": None},\n",
    "    ) \n",
    ")\n",
    "\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4655ee",
   "metadata": {},
   "source": [
    "##### FTW baseline, local tversky focal, standard augmentations\n",
    "\n",
    "This one is a redo to check that new version gives the same results as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42cb1085",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ma-ftwbase-localtfl-mmgab-sta\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"brightness\", \"rescale\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [203.544], \"max\": [4590.354], \n",
    "                      \"mean\": None, \"std\": None},\n",
    "    ) \n",
    ")\n",
    "\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e0f0d8",
   "metadata": {},
   "source": [
    "#### ConvNeXt, local tversky, minmax GAB, brightness and rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f59d0332",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ma-unet_cvnxt_sm-ltfl-sta-ep100\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(\n",
    "    max_epochs=100,\n",
    "    default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "        backbone=\"tu-convnext_small.fb_in22k\",\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"rescale\", \"brightness\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [203.544], \"max\": [4590.354], \n",
    "                      \"mean\": None, \"std\": None},\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade19d8b",
   "metadata": {},
   "source": [
    "#### Efficientnet-b7, local tversky, minmax GAB, brightness and rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f941e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 100\n",
    "cfg_name = \"ma-unet-effb7-ltfl-mnmx_gab-sta-ep100\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(\n",
    "    max_epochs=ep,\n",
    "    default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "        backbone=\"efficientnet-b7\",\n",
    "        patience=ep,\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"rescale\", \"brightness\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [203.544], \"max\": [4590.354], \n",
    "                      \"mean\": None, \"std\": None},\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a48af16",
   "metadata": {},
   "source": [
    "### Full catalog\n",
    "\n",
    "Setting up runs that will pull from the full catalog, starting with the FTW baseline model.\n",
    "\n",
    "We'll also specify some validation sets to evaluate results. To start we will use the separated FTW and Mapping Africa \"global\" validation samples, without confining them to specific countries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee01570",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_update = dict(\n",
    "    data=dict(\n",
    "        init_args=dict(\n",
    "            catalog=f\"{home_dir}/\"\\\n",
    "                \"ftw-mappingafrica-integration/data/ftw-mappingafrica-combined-catalog2.csv\"   \n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dccf5e",
   "metadata": {},
   "source": [
    "#### FTW Baseline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd54361c",
   "metadata": {},
   "source": [
    "##### # 1 Standard settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a249cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"fullcat-ftwbaseline-exp1\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef9d21",
   "metadata": {},
   "source": [
    "##### # 2 LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bec61aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"fullcat-ftwbaseline-exp2\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"data\"][\"init_args\"].update(dict(\n",
    "    normalization_strategy=\"min_max\",\n",
    "    normalization_stat_procedure=\"lab\",\n",
    "    global_stats=None,\n",
    "))\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc534f9",
   "metadata": {},
   "source": [
    "##### # 3 Locally-weighted tversky focal loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7073ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"fullcat-ftwbaseline-exp3\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(init_args=dict(loss=\"localtversky\"))\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8725b2ef",
   "metadata": {},
   "source": [
    "#### MA approximate baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c20104",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"fullcat-ma-approximate-baseline-exp1\"\n",
    "update = dict(\n",
    "    data=dict(\n",
    "        init_args=dict(\n",
    "            catalog=f\"{home_dir}/\"\\\n",
    "                \"ftw-mappingafrica-integration/data/ftw-mappingafrica-combined-catalog2.csv\"   \n",
    "        )\n",
    "    )\n",
    ")\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "write_yaml(\"../configs/ma-approximate-baseline.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441dd397",
   "metadata": {},
   "source": [
    "## Single time point, long catalog\n",
    "\n",
    "Re-running training for the full catalog and FTW only versions using the new long catalog.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6530e99",
   "metadata": {},
   "source": [
    "### FTW catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7153fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = \"~/projects\"\n",
    "base_update = dict(\n",
    "    data=dict(\n",
    "        init_args=dict(\n",
    "            catalog=f\"{home_dir}/\"\\\n",
    "                \"ftw-mappingafrica-integration/data/ftw-catalog-long2.csv\",\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be27238",
   "metadata": {},
   "source": [
    "#### FTW baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0284124",
   "metadata": {},
   "source": [
    "##### Locally-weighted tversky focal loss, redo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8713878",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ftwbaseline-localtversky-longcat\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(init_args=dict(loss=\"localtversky\"))\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b84efd",
   "metadata": {},
   "source": [
    "##### Tversky and min-max GAB, redo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "203d35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ftwbaseline-localtversky-minmax_gab-longcat\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(init_args=dict(loss=\"localtversky\"))\n",
    "update[\"data\"][\"init_args\"].update(dict(\n",
    "    normalization_strategy=\"min_max\",\n",
    "    normalization_stat_procedure=\"gab\",\n",
    "    global_stats={\"min\": [68.438525], \"max\": [5772.288821], \n",
    "                  \"mean\": None, \"std\": None},\n",
    "))\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff51b77c",
   "metadata": {},
   "source": [
    "##### Tversky, min-max GAB, photometric augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e9f9cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = [\"rotation\", \"hflip\", \"vflip\", \"sharpness\"]\n",
    "cfg_name = \"ftwbaseline-localtversky-minmax_gab-photometric-longcat\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(init_args=dict(loss=\"localtversky\"))\n",
    "update[\"data\"][\"init_args\"].update(dict(\n",
    "    aug_list=augs + [\"brightness\", \"contrast\", \"gaussian_noise\", \"gamma\"],\n",
    "    normalization_strategy=\"min_max\",\n",
    "    normalization_stat_procedure=\"gab\",\n",
    "    global_stats={\"min\": [68.438525], \"max\": [5772.288821], \n",
    "                  \"mean\": None, \"std\": None},\n",
    "))\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3f217c",
   "metadata": {},
   "source": [
    "##### Tversky, min-max GAB, photometric augmentations, rescale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76d31430",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ftwbaseline-localtversky-minmax_gab-photometric-rescale-longcat\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(init_args=dict(loss=\"localtversky\"))\n",
    "update[\"data\"][\"init_args\"].update(dict(\n",
    "    aug_list=augs + [\"rescale\", \"brightness\", \"contrast\", \"gaussian_noise\", \n",
    "                     \"gamma\"],\n",
    "    normalization_strategy=\"min_max\",\n",
    "    normalization_stat_procedure=\"gab\",\n",
    "    global_stats={\"min\": [68.438525], \"max\": [5772.288821], \n",
    "                  \"mean\": None, \"std\": None},\n",
    "))\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5af3be",
   "metadata": {},
   "source": [
    "##### Tversky, min-max GAB, brightness only, rescale\n",
    "\n",
    "Back to ftw-baseline. Note I tweaked the augmentation code to make this align now with FTW's brightness augmentation approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e92b5022",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ftwbaseline-localtversky-minmax_gab-brightness-rescale-longcat\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(init_args=dict(loss=\"localtversky\"))\n",
    "update[\"data\"][\"init_args\"].update(dict(\n",
    "    aug_list=augs + [\"rescale\", \"brightness\"],\n",
    "    normalization_strategy=\"min_max\",\n",
    "    normalization_stat_procedure=\"gab\",\n",
    "    global_stats={\"min\": [68.438525], \"max\": [5772.288821], \n",
    "                  \"mean\": None, \"std\": None},\n",
    "))\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec21d4e",
   "metadata": {},
   "source": [
    "##### SMP Tversky, min-max GAB, brightness only, rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e47c8e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ftwbase-smptversky-mnmx_gab-bright-rescale-longcat\"\n",
    "augs = [\"rotation\", \"hflip\", \"vflip\", \"sharpness\"]\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(init_args=dict(loss=\"tversky\"))\n",
    "update[\"data\"][\"init_args\"].update(dict(\n",
    "    aug_list=augs + [\"rescale\", \"brightness\"],\n",
    "    normalization_strategy=\"min_max\",\n",
    "    normalization_stat_procedure=\"gab\",\n",
    "    global_stats={\"min\": [68.438525], \"max\": [5772.288821], \n",
    "                  \"mean\": None, \"std\": None},\n",
    "))\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f2ebbe",
   "metadata": {},
   "source": [
    "##### Dice, min-max GAB, brightness only, rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e196985",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ftwbase-dice-mnmx_gab-bright-rescale-longcat\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(init_args=dict(loss=\"dice\"))\n",
    "update[\"data\"][\"init_args\"].update(dict(\n",
    "    aug_list=augs + [\"rescale\", \"brightness\"],\n",
    "    normalization_strategy=\"min_max\",\n",
    "    normalization_stat_procedure=\"gab\",\n",
    "    global_stats={\"min\": [68.438525], \"max\": [5772.288821], \n",
    "                  \"mean\": None, \"std\": None},\n",
    "))\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389143ee",
   "metadata": {},
   "source": [
    "##### logCoshDice, min-max GAB, brightness only, rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1886813",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ftwbase-logcoshdice-mnmx_gab-bright-rescale-longcat\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(init_args=dict(loss=\"logcoshdice\"))\n",
    "update[\"data\"][\"init_args\"].update(dict(\n",
    "    aug_list=augs + [\"rescale\", \"brightness\"],\n",
    "    normalization_strategy=\"min_max\",\n",
    "    normalization_stat_procedure=\"gab\",\n",
    "    global_stats={\"min\": [68.438525], \"max\": [5772.288821], \n",
    "                  \"mean\": None, \"std\": None},\n",
    "))\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffde4755",
   "metadata": {},
   "source": [
    "#### ConvNeXt backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df5eb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = \"~/projects\"\n",
    "base_update = dict(\n",
    "    data=dict(\n",
    "        init_args=dict(\n",
    "            catalog=f\"{home_dir}/\"\\\n",
    "                \"ftw-mappingafrica-integration/data/ftw-catalog-long2.csv\",\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acda713",
   "metadata": {},
   "source": [
    "##### Full augs, local-tversky\n",
    "\n",
    "We'll try out ConvNeXt small, pre-trained on ImageNet-22k. **Note**: the yaml should have been named differently (convnext_small-...). Also note this one had the wrong normalization stats procedure set (should have been gab, was lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf07164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"ftwbaseline-tversky-allaugs-convnext_small_in22k-longcat\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "        backbone=\"tu-convnext_small.fb_in22k\",\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + \\\n",
    "            [\"rescale\", \"brightness\", \"contrast\", \"gaussian_noise\", \"gamma\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"lab\",\n",
    "        global_stats={\"min\": [68.438525], \"max\": [5772.288821], \n",
    "                      \"mean\": None, \"std\": None}\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1714a302",
   "metadata": {},
   "source": [
    "##### ConvNext, local tversky, brightness & rescale, 300 epochs\n",
    "\n",
    "Ditching the additional photometrics augmentations since those are probably disappearing, and so the main thing here is to see if the model keeps learning. Validation curves from the model above suggested it had substantial improvements left. GAB normalization added as before. \n",
    "\n",
    "Note: I manually updated this one to 400 epochs after seeing continued gains at 300 epochs, and then again to 500 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca0ba02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"unet_cvnxt_sm_in22k-loctversky-brgt-rescl-e300-longcat\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(\n",
    "    max_epochs=300,\n",
    "    default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "        backbone=\"tu-convnext_small.fb_in22k\",\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"rescale\", \"brightness\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [68.438525], \"max\": [5772.288821], \n",
    "                      \"mean\": None, \"std\": None}\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790f4d81",
   "metadata": {},
   "source": [
    "##### ConvNext, local tversky, brightness & rescale, 300 epochs, different patience\n",
    "\n",
    "The ups and downs in learning on the long run from the one above seem to be resetting learning rate due to patience of 100 and cosine annealing. Will match patience to epochs to make continual progress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eac718c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"unet_cvnxt_sm-loctver-brgt-rescl-e300-p300-longcat\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(\n",
    "    max_epochs=300,\n",
    "    default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "        backbone=\"tu-convnext_small.fb_in22k\",\n",
    "        patience=300,\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"rescale\", \"brightness\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [68.438525], \"max\": [5772.288821], \n",
    "                      \"mean\": None, \"std\": None}\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b13a87",
   "metadata": {},
   "source": [
    "##### ConvNext, local tversky, brightness & rescale, 400 epochs\n",
    "\n",
    "The ups and downs in learning on the long run from the one above seem to be resetting learning rate due to patience of 100 and cosine annealing. Will match patience to epochs to make continual progress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f3b4459",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"unet_cvnxt_sm-ltfl-sta-ep400-longcat\"\n",
    "ep = 400\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(\n",
    "    max_epochs=ep,\n",
    "    default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "        backbone=\"tu-convnext_small.fb_in22k\",\n",
    "        patience=ep,\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"rescale\", \"brightness\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [68.438525], \"max\": [5772.288821], \n",
    "                      \"mean\": None, \"std\": None}\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824dad6c",
   "metadata": {},
   "source": [
    "##### ConvNext, logcoshdice, brightness & rescale, 400 epochs\n",
    "\n",
    "Trying best performing logcoshdice, which seems better than local tversky, although weak on object recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db3a9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"unet_cvnxt_sm_in22k-logcoshdice-brgt-rescl-e400-longcat\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(\n",
    "    max_epochs=400,\n",
    "    default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"logcoshdice\", \n",
    "        backbone=\"tu-convnext_small.fb_in22k\",\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"rescale\", \"brightness\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [68.438525], \"max\": [5772.288821], \n",
    "                      \"mean\": None, \"std\": None}\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baa5c4c",
   "metadata": {},
   "source": [
    "##### ConvNext, logcoshdice, brightness & rescale, 300 epochs, 300 patience\n",
    "\n",
    "Above with LR not resetting due to patience being too short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85e7b494",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"unet_cvnxt_sm-logcoshdice-brgt-rescl-e400-p300-longcat\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(\n",
    "    max_epochs=400,\n",
    "    default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"logcoshdice\", \n",
    "        backbone=\"tu-convnext_small.fb_in22k\",\n",
    "        patience=300,\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"rescale\", \"brightness\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [68.438525], \"max\": [5772.288821], \n",
    "                      \"mean\": None, \"std\": None}\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451bb072",
   "metadata": {},
   "source": [
    "#### EfficientNet-b7, 400 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "321c5478",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 400\n",
    "cfg_name = \"unet-effb7-ltfl-mmgab-sta-ep400-longcat\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(\n",
    "    max_epochs=ep,\n",
    "    default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "        backbone=\"efficientnet-b7\",\n",
    "        patience=ep,\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"rescale\", \"brightness\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [68.438525], \"max\": [5772.288821], \n",
    "                      \"mean\": None, \"std\": None}\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265dfe64",
   "metadata": {},
   "source": [
    "### Full catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3088c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = \"~/projects\"\n",
    "augs = [\"rotation\", \"hflip\", \"vflip\", \"sharpness\"]\n",
    "base_update = dict(\n",
    "    data=dict(\n",
    "        init_args=dict(\n",
    "            catalog=f\"{home_dir}/\"\\\n",
    "                f\"ftw-mappingafrica-integration/data/\"\\\n",
    "                    \"ftw-mappingafrica-combined-catalog-long2.csv\"   \n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34272579",
   "metadata": {},
   "source": [
    "#### FTW base, local tversky, GAB, brightness & rescale, 100 epochs\n",
    "\n",
    "Maybe extend longer depending on curves. Keeping patience at 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "277f0db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"full-ftwbase-loctver-mnmx_gab-brgt-rescl2\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"brightness\", \"rescale\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [89.1], \"max\": [5528.3], \n",
    "                      \"mean\": None, \"std\": None},\n",
    "    ) \n",
    ")\n",
    "\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c863e52",
   "metadata": {},
   "source": [
    "#### FTW base, SMP tversky, GAB, brightness & rescale, 100 epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8549bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"full-ftwbase-smptver-mnmx_gab-brgt-rescl2\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"tversky\", \n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"brightness\", \"rescale\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [89.1], \"max\": [5528.3], \n",
    "                      \"mean\": None, \"std\": None},\n",
    "    ) \n",
    ")\n",
    "\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc434559",
   "metadata": {},
   "source": [
    "#### MA approximate, local tversky, GAB, brightness & rescale, 100 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93c0756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"full-ma-approx-mnmx_gab-brgt-rescl2\"\n",
    "\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "        backbone=\"tu-vgg19_bn.tv_in1k\",\n",
    "        patch_weights=True,\n",
    "        model_kwargs=dict(drop_rate=0.1)\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"brightness\", \"rescale\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [89.1], \"max\": [5528.3], \n",
    "                      \"mean\": None, \"std\": None},\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23816a58",
   "metadata": {},
   "source": [
    "#### MA approximate, smp tversky, GAB, brightness & rescale, 100 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9812730",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"full-ma-approx-smptver-mnmx_gab-brgt-rescl2\"\n",
    "\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"tversky\", \n",
    "        backbone=\"tu-vgg19_bn.tv_in1k\",\n",
    "        patch_weights=True,\n",
    "        model_kwargs=dict(drop_rate=0.1)\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"brightness\", \"rescale\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [89.1], \"max\": [5528.3], \n",
    "                      \"mean\": None, \"std\": None},\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef992f",
   "metadata": {},
   "source": [
    "#### ConvNext, local tversky, brightness & rescale, 300 epochs, 300 patience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bd44dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 400\n",
    "cfg_name = \"full-unet_cvnxt_sm-ltfl-sta-ep400\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(\n",
    "    max_epochs=ep,\n",
    "    default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "        backbone=\"tu-convnext_small.fb_in22k\",\n",
    "        patience=ep,\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"rescale\", \"brightness\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [89.1], \"max\": [5528.3],\n",
    "                      \"mean\": None, \"std\": None}\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ace531",
   "metadata": {},
   "source": [
    "#### EfficientNet-b7, 400 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b74446db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 400\n",
    "cfg_name = \"full-unet-effb7-ltfl-mmgab-sta-ep400\"\n",
    "update = base_update.copy()\n",
    "update[\"trainer\"] = dict(\n",
    "    max_epochs=ep,\n",
    "    default_root_dir=f\"~/working/models/{cfg_name}\")\n",
    "update[\"model\"] = dict(\n",
    "    init_args=dict(\n",
    "        class_weights=None,\n",
    "        loss=\"localtversky\", \n",
    "        backbone=\"efficientnet-b7\",\n",
    "        patience=ep,\n",
    "    )\n",
    ")\n",
    "update[\"data\"][\"init_args\"].update(\n",
    "    dict(\n",
    "        aug_list=augs + [\"rescale\", \"brightness\"],\n",
    "        normalization_strategy=\"min_max\",\n",
    "        normalization_stat_procedure=\"gab\",\n",
    "        global_stats={\"min\": [89.1], \"max\": [5528.3],\n",
    "                      \"mean\": None, \"std\": None}\n",
    "    ) \n",
    ")\n",
    "write_yaml(\"../configs/template-hpc-config.yaml\", \n",
    "           f\"../configs/{cfg_name}.yaml\", \n",
    "           updates=update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ftw-mapafrica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
